{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks Today:\n",
    "\n",
    "0) <b>Pre-Work</b> <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; a) Numpy Random Sampling\n",
    "\n",
    "1) <b>Pandas</b> <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; a) Importing <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; b) Tabular Data Structures <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - from_dict() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - read_csv() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; c) <b>In-Class Exercise #1</b> <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; d) Accessing Data <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Indexing <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - df.loc <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - keys() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Slicing a DataFrame <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; e) Built-In Methods <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - head() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - tail() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - shape <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - describe() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - sort_values() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - .columns <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; f) <b>In-Class Exercise #2</b> <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; g) Filtration <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Conditionals <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Subsetting <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; h) Column Transformations <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Generating a New Column w/Data <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - User Defined Function <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; i) Aggregations <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - groupby() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Type of groupby() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - mean() <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - groupby() w/Multiple Columns <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - drop_duplicates() <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a random number: 0.6151942736498733\n",
      "Here is a random number between 0 and 1 Million: 844232.1849260223\n",
      "Here are 3 random numbers between 0 and 10: [7.76780899 5.04651204 2.61279064]\n",
      "Here is a 3x3 matrix with numbers between 0 and 10: \n",
      " [[4.85711677 5.43862887 0.75883063]\n",
      " [2.55643739 5.8275338  6.65834459]\n",
      " [3.01310855 7.89514004 7.23634413]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# np.random.uniform()\n",
    "\n",
    "# A single call generates a single random number between 0 and 1\n",
    "\n",
    "print('Here is a random number: %s' % np.random.uniform())\n",
    "\n",
    "# You can also pass some parameters or bounds\n",
    "\n",
    "print('Here is a random number between 0 and 1 Million: %s' % np.random.uniform(0, 1e6))\n",
    "\n",
    "# You can also generate a bunch of random numbers all at once\n",
    "\n",
    "print('Here are 3 random numbers between 0 and 10: %s' % np.random.uniform(0, 10, 3))\n",
    "\n",
    "# Even matrices with shapes as a parameter\n",
    "\n",
    "print('Here is a 3x3 matrix with numbers between 0 and 10: \\n %s' % np.random.uniform(0, 10, (3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas <br>\n",
    "\n",
    "<p>Pandas is a flexible data analysis library built on top of NumPy that is excellent for working with tabular data. It is currently the de-facto standard for Python-based data analysis, and fluency in Pandas will do wonders for your productivity and frankly your resume. It is one of the fastest ways of getting from zero to answer in existence. </p>\n",
    "\n",
    "<ul>\n",
    "    <li>Pandas is a Python module, written in C. The Pandas module is a high performance, highly efficient, and high level data analysis library. It allows us to work with large sets of data called dataframes.</li>\n",
    "    <li>Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.)</li>\n",
    "    <li>Dataframe = Spreadsheet (has column headers, index, etc.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kunle kuforiji\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kunle kuforiji\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kunle kuforiji\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kunle kuforiji\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\kunle kuforiji\\anaconda3\\lib\\site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kunle kuforiji\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# always use pd, standard for data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular data structures <br>\n",
    "<p>The central object of study in Pandas is the DataFrame, which is a tabular data structure with rows and columns like an excel spreadsheet. The first point of discussion is the creation of dataframes both from native Python dictionaries, and text files through the Pandas I/O system.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('names',\n",
       " ['Ola', 'Bukky', 'Margaret', 'Kunle', 'Subomi', 'Posi', 'Anjola', 'Kuforiji'],\n",
       " 'ages',\n",
       " array([18, 24, 19, 27, 31, 32, 33, 23]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['Ola',\n",
    "        'Bukky',\n",
    "        'Margaret',\n",
    "        'Kunle',\n",
    "        'Subomi',\n",
    "        'Posi',\n",
    "        'Anjola',\n",
    "        'Kuforiji']\n",
    "\n",
    "ages = np.random.randint(18,35,len(names))\n",
    "\n",
    "my_people = (\n",
    "    'names', names,\n",
    "    'ages',ages)\n",
    "\n",
    "my_people\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### from_dict()\n",
    "\n",
    "<p>Let's convert our not-so-useful-for-analysis dict into a Pandas dataframe. We can use the from_dict function to do this easily using Pandas:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>names</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Ola, Bukky, Margaret, Kunle, Subomi, Posi, An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[31, 22, 18, 25, 26, 33, 21, 20]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                              names\n",
       "1  [Ola, Bukky, Margaret, Kunle, Subomi, Posi, An...\n",
       "2                                               ages\n",
       "3                   [31, 22, 18, 25, 26, 33, 21, 20]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =pd.DataFrame.from_dict(my_people)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10K</th>\n",
       "      <th>15K</th>\n",
       "      <th>20K</th>\n",
       "      <th>25K</th>\n",
       "      <th>30K</th>\n",
       "      <th>35K</th>\n",
       "      <th>40K</th>\n",
       "      <th>5K</th>\n",
       "      <th>Age</th>\n",
       "      <th>Bib</th>\n",
       "      <th>...</th>\n",
       "      <th>Division</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Half</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Name</th>\n",
       "      <th>Number of Records</th>\n",
       "      <th>Official Time</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Pace</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/30/1899 12:30:28 AM</td>\n",
       "      <td>12/30/1899 12:45:44 AM</td>\n",
       "      <td>12/30/1899 1:01:15 AM</td>\n",
       "      <td>12/30/1899 1:16:59 AM</td>\n",
       "      <td>12/30/1899 1:33:01 AM</td>\n",
       "      <td>12/30/1899 1:48:19 AM</td>\n",
       "      <td>12/30/1899 2:02:53 AM</td>\n",
       "      <td>12/30/1899 12:15:25 AM</td>\n",
       "      <td>24</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 1:04:35 AM</td>\n",
       "      <td>M</td>\n",
       "      <td>Kirui, Geoffrey</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 2:09:37 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 12:04:57 AM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/30/1899 12:30:27 AM</td>\n",
       "      <td>12/30/1899 12:45:44 AM</td>\n",
       "      <td>12/30/1899 1:01:15 AM</td>\n",
       "      <td>12/30/1899 1:16:59 AM</td>\n",
       "      <td>12/30/1899 1:33:01 AM</td>\n",
       "      <td>12/30/1899 1:48:19 AM</td>\n",
       "      <td>12/30/1899 2:03:14 AM</td>\n",
       "      <td>12/30/1899 12:15:24 AM</td>\n",
       "      <td>30</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12/30/1899 1:04:35 AM</td>\n",
       "      <td>M</td>\n",
       "      <td>Rupp, Galen</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 2:09:58 AM</td>\n",
       "      <td>2</td>\n",
       "      <td>12/30/1899 12:04:58 AM</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/30/1899 12:30:29 AM</td>\n",
       "      <td>12/30/1899 12:45:44 AM</td>\n",
       "      <td>12/30/1899 1:01:16 AM</td>\n",
       "      <td>12/30/1899 1:17:00 AM</td>\n",
       "      <td>12/30/1899 1:33:01 AM</td>\n",
       "      <td>12/30/1899 1:48:31 AM</td>\n",
       "      <td>12/30/1899 2:03:38 AM</td>\n",
       "      <td>12/30/1899 12:15:25 AM</td>\n",
       "      <td>25</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12/30/1899 1:04:36 AM</td>\n",
       "      <td>M</td>\n",
       "      <td>Osako, Suguru</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 2:10:28 AM</td>\n",
       "      <td>3</td>\n",
       "      <td>12/30/1899 12:04:59 AM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/30/1899 12:30:29 AM</td>\n",
       "      <td>12/30/1899 12:45:44 AM</td>\n",
       "      <td>12/30/1899 1:01:19 AM</td>\n",
       "      <td>12/30/1899 1:17:00 AM</td>\n",
       "      <td>12/30/1899 1:33:01 AM</td>\n",
       "      <td>12/30/1899 1:48:58 AM</td>\n",
       "      <td>12/30/1899 2:04:35 AM</td>\n",
       "      <td>12/30/1899 12:15:25 AM</td>\n",
       "      <td>32</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12/30/1899 1:04:45 AM</td>\n",
       "      <td>M</td>\n",
       "      <td>Biwott, Shadrack</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 2:12:08 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>12/30/1899 12:05:03 AM</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/30/1899 12:30:28 AM</td>\n",
       "      <td>12/30/1899 12:45:44 AM</td>\n",
       "      <td>12/30/1899 1:01:15 AM</td>\n",
       "      <td>12/30/1899 1:16:59 AM</td>\n",
       "      <td>12/30/1899 1:33:01 AM</td>\n",
       "      <td>12/30/1899 1:48:41 AM</td>\n",
       "      <td>12/30/1899 2:05:00 AM</td>\n",
       "      <td>12/30/1899 12:15:25 AM</td>\n",
       "      <td>31</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12/30/1899 1:04:35 AM</td>\n",
       "      <td>M</td>\n",
       "      <td>Chebet, Wilson</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 2:12:35 AM</td>\n",
       "      <td>5</td>\n",
       "      <td>12/30/1899 12:05:04 AM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26405</th>\n",
       "      <td>12/30/1899 1:35:41 AM</td>\n",
       "      <td>12/30/1899 2:23:35 AM</td>\n",
       "      <td>12/30/1899 3:12:44 AM</td>\n",
       "      <td>12/30/1899 4:12:06 AM</td>\n",
       "      <td>12/30/1899 5:03:08 AM</td>\n",
       "      <td>12/30/1899 5:55:18 AM</td>\n",
       "      <td>12/30/1899 6:46:57 AM</td>\n",
       "      <td>12/30/1899 12:46:44 AM</td>\n",
       "      <td>61</td>\n",
       "      <td>25166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>344</td>\n",
       "      <td>11972</td>\n",
       "      <td>12/30/1899 3:23:31 AM</td>\n",
       "      <td>F</td>\n",
       "      <td>Steinbach, Paula Eyvonne</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 7:09:39 AM</td>\n",
       "      <td>26407</td>\n",
       "      <td>12/30/1899 12:16:24 AM</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26406</th>\n",
       "      <td>12/30/1899 1:05:33 AM</td>\n",
       "      <td>12/30/1899 1:52:17 AM</td>\n",
       "      <td>12/30/1899 2:49:41 AM</td>\n",
       "      <td>12/30/1899 3:50:19 AM</td>\n",
       "      <td>12/30/1899 4:50:01 AM</td>\n",
       "      <td>12/30/1899 5:53:48 AM</td>\n",
       "      <td>12/30/1899 6:54:21 AM</td>\n",
       "      <td>12/30/1899 12:32:03 AM</td>\n",
       "      <td>25</td>\n",
       "      <td>25178.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4774</td>\n",
       "      <td>14436</td>\n",
       "      <td>12/30/1899 3:00:26 AM</td>\n",
       "      <td>M</td>\n",
       "      <td>Avelino, Andrew R.</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 7:16:59 AM</td>\n",
       "      <td>26408</td>\n",
       "      <td>12/30/1899 12:16:40 AM</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26407</th>\n",
       "      <td>12/30/1899 1:43:36 AM</td>\n",
       "      <td>12/30/1899 2:32:36 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/30/1899 4:15:21 AM</td>\n",
       "      <td>12/30/1899 5:06:37 AM</td>\n",
       "      <td>12/30/1899 6:00:33 AM</td>\n",
       "      <td>12/30/1899 6:54:38 AM</td>\n",
       "      <td>12/30/1899 12:53:11 AM</td>\n",
       "      <td>57</td>\n",
       "      <td>27086.0</td>\n",
       "      <td>...</td>\n",
       "      <td>698</td>\n",
       "      <td>11973</td>\n",
       "      <td>12/30/1899 3:36:24 AM</td>\n",
       "      <td>F</td>\n",
       "      <td>Hantel, Johanna</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 7:19:37 AM</td>\n",
       "      <td>26409</td>\n",
       "      <td>12/30/1899 12:16:47 AM</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26408</th>\n",
       "      <td>12/30/1899 1:27:19 AM</td>\n",
       "      <td>12/30/1899 2:17:17 AM</td>\n",
       "      <td>12/30/1899 3:11:40 AM</td>\n",
       "      <td>12/30/1899 4:06:10 AM</td>\n",
       "      <td>12/30/1899 5:07:09 AM</td>\n",
       "      <td>12/30/1899 6:06:07 AM</td>\n",
       "      <td>12/30/1899 6:56:08 AM</td>\n",
       "      <td>12/30/1899 12:40:34 AM</td>\n",
       "      <td>64</td>\n",
       "      <td>25268.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1043</td>\n",
       "      <td>14437</td>\n",
       "      <td>12/30/1899 3:22:30 AM</td>\n",
       "      <td>M</td>\n",
       "      <td>Reilly, Bill</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 7:20:44 AM</td>\n",
       "      <td>26410</td>\n",
       "      <td>12/30/1899 12:16:49 AM</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26409</th>\n",
       "      <td>12/30/1899 1:17:12 AM</td>\n",
       "      <td>12/30/1899 2:00:10 AM</td>\n",
       "      <td>12/30/1899 2:58:55 AM</td>\n",
       "      <td>12/30/1899 4:27:14 AM</td>\n",
       "      <td>12/30/1899 5:37:13 AM</td>\n",
       "      <td>12/30/1899 6:39:07 AM</td>\n",
       "      <td>12/30/1899 7:41:23 AM</td>\n",
       "      <td>12/30/1899 12:39:36 AM</td>\n",
       "      <td>48</td>\n",
       "      <td>25266.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2553</td>\n",
       "      <td>14438</td>\n",
       "      <td>12/30/1899 3:08:16 AM</td>\n",
       "      <td>M</td>\n",
       "      <td>Rigsby, Scott</td>\n",
       "      <td>1</td>\n",
       "      <td>12/30/1899 7:58:14 AM</td>\n",
       "      <td>26411</td>\n",
       "      <td>12/30/1899 12:18:15 AM</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26410 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          10K                     15K                    20K  \\\n",
       "0      12/30/1899 12:30:28 AM  12/30/1899 12:45:44 AM  12/30/1899 1:01:15 AM   \n",
       "1      12/30/1899 12:30:27 AM  12/30/1899 12:45:44 AM  12/30/1899 1:01:15 AM   \n",
       "2      12/30/1899 12:30:29 AM  12/30/1899 12:45:44 AM  12/30/1899 1:01:16 AM   \n",
       "3      12/30/1899 12:30:29 AM  12/30/1899 12:45:44 AM  12/30/1899 1:01:19 AM   \n",
       "4      12/30/1899 12:30:28 AM  12/30/1899 12:45:44 AM  12/30/1899 1:01:15 AM   \n",
       "...                       ...                     ...                    ...   \n",
       "26405   12/30/1899 1:35:41 AM   12/30/1899 2:23:35 AM  12/30/1899 3:12:44 AM   \n",
       "26406   12/30/1899 1:05:33 AM   12/30/1899 1:52:17 AM  12/30/1899 2:49:41 AM   \n",
       "26407   12/30/1899 1:43:36 AM   12/30/1899 2:32:36 AM                    NaN   \n",
       "26408   12/30/1899 1:27:19 AM   12/30/1899 2:17:17 AM  12/30/1899 3:11:40 AM   \n",
       "26409   12/30/1899 1:17:12 AM   12/30/1899 2:00:10 AM  12/30/1899 2:58:55 AM   \n",
       "\n",
       "                         25K                    30K                    35K  \\\n",
       "0      12/30/1899 1:16:59 AM  12/30/1899 1:33:01 AM  12/30/1899 1:48:19 AM   \n",
       "1      12/30/1899 1:16:59 AM  12/30/1899 1:33:01 AM  12/30/1899 1:48:19 AM   \n",
       "2      12/30/1899 1:17:00 AM  12/30/1899 1:33:01 AM  12/30/1899 1:48:31 AM   \n",
       "3      12/30/1899 1:17:00 AM  12/30/1899 1:33:01 AM  12/30/1899 1:48:58 AM   \n",
       "4      12/30/1899 1:16:59 AM  12/30/1899 1:33:01 AM  12/30/1899 1:48:41 AM   \n",
       "...                      ...                    ...                    ...   \n",
       "26405  12/30/1899 4:12:06 AM  12/30/1899 5:03:08 AM  12/30/1899 5:55:18 AM   \n",
       "26406  12/30/1899 3:50:19 AM  12/30/1899 4:50:01 AM  12/30/1899 5:53:48 AM   \n",
       "26407  12/30/1899 4:15:21 AM  12/30/1899 5:06:37 AM  12/30/1899 6:00:33 AM   \n",
       "26408  12/30/1899 4:06:10 AM  12/30/1899 5:07:09 AM  12/30/1899 6:06:07 AM   \n",
       "26409  12/30/1899 4:27:14 AM  12/30/1899 5:37:13 AM  12/30/1899 6:39:07 AM   \n",
       "\n",
       "                         40K                      5K  Age      Bib  ...  \\\n",
       "0      12/30/1899 2:02:53 AM  12/30/1899 12:15:25 AM   24     11.0  ...   \n",
       "1      12/30/1899 2:03:14 AM  12/30/1899 12:15:24 AM   30     17.0  ...   \n",
       "2      12/30/1899 2:03:38 AM  12/30/1899 12:15:25 AM   25     23.0  ...   \n",
       "3      12/30/1899 2:04:35 AM  12/30/1899 12:15:25 AM   32     21.0  ...   \n",
       "4      12/30/1899 2:05:00 AM  12/30/1899 12:15:25 AM   31      9.0  ...   \n",
       "...                      ...                     ...  ...      ...  ...   \n",
       "26405  12/30/1899 6:46:57 AM  12/30/1899 12:46:44 AM   61  25166.0  ...   \n",
       "26406  12/30/1899 6:54:21 AM  12/30/1899 12:32:03 AM   25  25178.0  ...   \n",
       "26407  12/30/1899 6:54:38 AM  12/30/1899 12:53:11 AM   57  27086.0  ...   \n",
       "26408  12/30/1899 6:56:08 AM  12/30/1899 12:40:34 AM   64  25268.0  ...   \n",
       "26409  12/30/1899 7:41:23 AM  12/30/1899 12:39:36 AM   48  25266.0  ...   \n",
       "\n",
       "       Division Gender                   Half  M/F                      Name  \\\n",
       "0             1      1  12/30/1899 1:04:35 AM    M           Kirui, Geoffrey   \n",
       "1             2      2  12/30/1899 1:04:35 AM    M               Rupp, Galen   \n",
       "2             3      3  12/30/1899 1:04:36 AM    M             Osako, Suguru   \n",
       "3             4      4  12/30/1899 1:04:45 AM    M          Biwott, Shadrack   \n",
       "4             5      5  12/30/1899 1:04:35 AM    M            Chebet, Wilson   \n",
       "...         ...    ...                    ...  ...                       ...   \n",
       "26405       344  11972  12/30/1899 3:23:31 AM    F  Steinbach, Paula Eyvonne   \n",
       "26406      4774  14436  12/30/1899 3:00:26 AM    M        Avelino, Andrew R.   \n",
       "26407       698  11973  12/30/1899 3:36:24 AM    F           Hantel, Johanna   \n",
       "26408      1043  14437  12/30/1899 3:22:30 AM    M              Reilly, Bill   \n",
       "26409      2553  14438  12/30/1899 3:08:16 AM    M             Rigsby, Scott   \n",
       "\n",
       "      Number of Records          Official Time  Overall  \\\n",
       "0                     1  12/30/1899 2:09:37 AM        1   \n",
       "1                     1  12/30/1899 2:09:58 AM        2   \n",
       "2                     1  12/30/1899 2:10:28 AM        3   \n",
       "3                     1  12/30/1899 2:12:08 AM        4   \n",
       "4                     1  12/30/1899 2:12:35 AM        5   \n",
       "...                 ...                    ...      ...   \n",
       "26405                 1  12/30/1899 7:09:39 AM    26407   \n",
       "26406                 1  12/30/1899 7:16:59 AM    26408   \n",
       "26407                 1  12/30/1899 7:19:37 AM    26409   \n",
       "26408                 1  12/30/1899 7:20:44 AM    26410   \n",
       "26409                 1  12/30/1899 7:58:14 AM    26411   \n",
       "\n",
       "                         Pace State  \n",
       "0      12/30/1899 12:04:57 AM   NaN  \n",
       "1      12/30/1899 12:04:58 AM    OR  \n",
       "2      12/30/1899 12:04:59 AM   NaN  \n",
       "3      12/30/1899 12:05:03 AM    CA  \n",
       "4      12/30/1899 12:05:04 AM   NaN  \n",
       "...                       ...   ...  \n",
       "26405  12/30/1899 12:16:24 AM    CA  \n",
       "26406  12/30/1899 12:16:40 AM    NC  \n",
       "26407  12/30/1899 12:16:47 AM    PA  \n",
       "26408  12/30/1899 12:16:49 AM    NY  \n",
       "26409  12/30/1899 12:18:15 AM    GA  \n",
       "\n",
       "[26410 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "marathon = pd.read_csv('boston_marathon2017_edited - boston_marathon2017_edited.csv',sep =',')\n",
    "marathon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Class Exercise #1 - Read in Boston Red Sox Hitting Data <br>\n",
    "<p>Use the pandas read_csv() method to read in the statistics from the two files yesterday.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>...</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>OPS+</th>\n",
       "      <th>TB</th>\n",
       "      <th>GDP</th>\n",
       "      <th>HBP</th>\n",
       "      <th>SH</th>\n",
       "      <th>SF</th>\n",
       "      <th>IBB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>Christian Vazquez</td>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "      <td>345</td>\n",
       "      <td>324</td>\n",
       "      <td>43</td>\n",
       "      <td>94</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.735</td>\n",
       "      <td>91</td>\n",
       "      <td>131</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1B</td>\n",
       "      <td>Mitch Moreland</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>576</td>\n",
       "      <td>508</td>\n",
       "      <td>73</td>\n",
       "      <td>125</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.769</td>\n",
       "      <td>99</td>\n",
       "      <td>225</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2B</td>\n",
       "      <td>Dustin Pedroia</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>463</td>\n",
       "      <td>406</td>\n",
       "      <td>46</td>\n",
       "      <td>119</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.760</td>\n",
       "      <td>100</td>\n",
       "      <td>159</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SS</td>\n",
       "      <td>Xander Bogaerts</td>\n",
       "      <td>24</td>\n",
       "      <td>148</td>\n",
       "      <td>635</td>\n",
       "      <td>571</td>\n",
       "      <td>94</td>\n",
       "      <td>156</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.746</td>\n",
       "      <td>95</td>\n",
       "      <td>230</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3B</td>\n",
       "      <td>Rafael Devers</td>\n",
       "      <td>20</td>\n",
       "      <td>58</td>\n",
       "      <td>240</td>\n",
       "      <td>222</td>\n",
       "      <td>34</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.819</td>\n",
       "      <td>111</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>LF</td>\n",
       "      <td>Andrew Benintendi</td>\n",
       "      <td>22</td>\n",
       "      <td>151</td>\n",
       "      <td>658</td>\n",
       "      <td>573</td>\n",
       "      <td>84</td>\n",
       "      <td>155</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.776</td>\n",
       "      <td>102</td>\n",
       "      <td>243</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>CF</td>\n",
       "      <td>Jackie Bradley Jr.</td>\n",
       "      <td>27</td>\n",
       "      <td>133</td>\n",
       "      <td>541</td>\n",
       "      <td>482</td>\n",
       "      <td>58</td>\n",
       "      <td>118</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.726</td>\n",
       "      <td>89</td>\n",
       "      <td>194</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>RF</td>\n",
       "      <td>Mookie Betts</td>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>712</td>\n",
       "      <td>628</td>\n",
       "      <td>101</td>\n",
       "      <td>166</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.803</td>\n",
       "      <td>108</td>\n",
       "      <td>288</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>DH</td>\n",
       "      <td>Hanley Ramirez</td>\n",
       "      <td>33</td>\n",
       "      <td>133</td>\n",
       "      <td>553</td>\n",
       "      <td>496</td>\n",
       "      <td>58</td>\n",
       "      <td>120</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>94</td>\n",
       "      <td>213</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>C</td>\n",
       "      <td>Sandy Leon</td>\n",
       "      <td>28</td>\n",
       "      <td>85</td>\n",
       "      <td>301</td>\n",
       "      <td>271</td>\n",
       "      <td>32</td>\n",
       "      <td>61</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.644</td>\n",
       "      <td>68</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>UT</td>\n",
       "      <td>Chris Young</td>\n",
       "      <td>33</td>\n",
       "      <td>90</td>\n",
       "      <td>276</td>\n",
       "      <td>243</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.709</td>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>3B</td>\n",
       "      <td>Deven Marrero</td>\n",
       "      <td>26</td>\n",
       "      <td>71</td>\n",
       "      <td>188</td>\n",
       "      <td>171</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.593</td>\n",
       "      <td>54</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2B</td>\n",
       "      <td>Eduardo Nunez</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>173</td>\n",
       "      <td>165</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.892</td>\n",
       "      <td>128</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2B</td>\n",
       "      <td>Brock Holt</td>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>164</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.548</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>IF</td>\n",
       "      <td>Josh Rutledge</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>118</td>\n",
       "      <td>107</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.558</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3B</td>\n",
       "      <td>Pablo Sandoval</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>108</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.622</td>\n",
       "      <td>61</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>UT</td>\n",
       "      <td>Sam Travis</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>83</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.667</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>UT</td>\n",
       "      <td>Tzu-Wei Lin</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.709</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>IF</td>\n",
       "      <td>Marco Hernandez</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.628</td>\n",
       "      <td>65</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>UT</td>\n",
       "      <td>Rajai Davis</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.595</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>UT</td>\n",
       "      <td>Steve Selsky</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>UT</td>\n",
       "      <td>Blake Swihart</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.629</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2B</td>\n",
       "      <td>Chase d'Arnaud</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rk Pos                Name  Age    G   PA   AB    R    H  2B  ...    OBP  \\\n",
       "0    1   C   Christian Vazquez   26   99  345  324   43   94  18  ...  0.330   \n",
       "1    2  1B      Mitch Moreland   31  149  576  508   73  125  34  ...  0.326   \n",
       "2    3  2B      Dustin Pedroia   33  105  463  406   46  119  19  ...  0.369   \n",
       "3    4  SS     Xander Bogaerts   24  148  635  571   94  156  32  ...  0.343   \n",
       "4    5  3B       Rafael Devers   20   58  240  222   34   63  14  ...  0.338   \n",
       "5    6  LF   Andrew Benintendi   22  151  658  573   84  155  26  ...  0.352   \n",
       "6    7  CF  Jackie Bradley Jr.   27  133  541  482   58  118  19  ...  0.323   \n",
       "7    8  RF        Mookie Betts   24  153  712  628  101  166  46  ...  0.344   \n",
       "8    9  DH      Hanley Ramirez   33  133  553  496   58  120  24  ...  0.320   \n",
       "9   10   C          Sandy Leon   28   85  301  271   32   61  14  ...  0.290   \n",
       "10  11  UT         Chris Young   33   90  276  243   30   57  12  ...  0.322   \n",
       "11  12  3B       Deven Marrero   26   71  188  171   32   36   9  ...  0.259   \n",
       "12  13  2B       Eduardo Nunez   30   38  173  165   23   53  12  ...  0.353   \n",
       "13  14  2B          Brock Holt   29   64  164  140   20   28   6  ...  0.305   \n",
       "14  15  IF       Josh Rutledge   28   37  118  107   10   24   2  ...  0.297   \n",
       "15  16  3B      Pablo Sandoval   30   32  108   99   10   21   2  ...  0.269   \n",
       "16  17  UT          Sam Travis   23   33   83   76   13   20   6  ...  0.325   \n",
       "17  18  UT         Tzu-Wei Lin   23   25   66   56    7   15   0  ...  0.369   \n",
       "18  19  IF     Marco Hernandez   24   21   60   58    7   16   3  ...  0.300   \n",
       "19  20  UT         Rajai Davis   36   17   38   36    7    9   2  ...  0.289   \n",
       "20  21  UT        Steve Selsky   27    8    9    9    0    1   1  ...  0.111   \n",
       "21  22  UT       Blake Swihart   25    6    7    5    1    1   0  ...  0.429   \n",
       "22  23  2B      Chase d'Arnaud   30    2    1    1    2    1   0  ...  1.000   \n",
       "\n",
       "      SLG    OPS  OPS+   TB  GDP  HBP  SH  SF  IBB  \n",
       "0   0.404  0.735    91  131   14    3   0   1    0  \n",
       "1   0.443  0.769    99  225   14    6   0   5    6  \n",
       "2   0.392  0.760   100  159   11    2   2   4    4  \n",
       "3   0.403  0.746    95  230   17    6   0   2    6  \n",
       "4   0.482  0.819   111  107    5    0   0   0    3  \n",
       "5   0.424  0.776   102  243   16    6   1   8    7  \n",
       "6   0.402  0.726    89  194    8    9   0   2    4  \n",
       "7   0.459  0.803   108  288    9    2   0   5    9  \n",
       "8   0.429  0.750    94  213   15    6   0   0    8  \n",
       "9   0.354  0.644    68   96    5    1   1   3    1  \n",
       "10  0.387  0.709    85   94    4    2   0   1    0  \n",
       "11  0.333  0.593    54   57    8    0   3   2    0  \n",
       "12  0.539  0.892   128   89    3    2   0   0    0  \n",
       "13  0.243  0.548    47   34    3    3   0   2    0  \n",
       "14  0.262  0.558    49   28    1    2   0   0    0  \n",
       "15  0.354  0.622    61   35    4    0   0   1    0  \n",
       "16  0.342  0.667    75   26    2    1   0   0    0  \n",
       "17  0.339  0.709    88   19    0    0   1   0    0  \n",
       "18  0.328  0.628    65   19    0    1   0   0    0  \n",
       "19  0.306  0.595    56   11    2    1   0   0    0  \n",
       "20  0.222  0.333   -16    2    0    0   0   0    0  \n",
       "21  0.200  0.629    74    1    0    0   0   0    0  \n",
       "22  1.000  2.000   428    1    0    0   0   0    0  \n",
       "\n",
       "[23 rows x 28 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos17 = pd.read_csv('Boston Red Sox hitting data 2017.csv',sep =',')\n",
    "bos18 = pd.read_csv('Boston Red Sox hitting data 2018.csv',sep =',')\n",
    "bos17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Data <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Indexing\n",
    "\n",
    "<p>You can directly select a column of a dataframe just like you would a dict. The result is a Pandas 'Series' object.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Access the 'Name' column\n",
    "name_column = df['Name']\n",
    "\n",
    "print(name_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df.loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Along the horizontal dimension, rows of Pandas DataFrames are Row objects. You will notice there is a third column present in the DataFrame - this is the $\\textit{index}$. It is automatically generated as a row number, but can be reassigned to a column of your choice using the DataFrame.set_index(colname) method. We can use it to access particular Pandas $\\textit{rows}$, which are also Series objects:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age           City\n",
      "0    Alice   25       New York\n",
      "1      Bob   30  San Francisco\n",
      "2  Charlie   35    Los Angeles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Name', 'Age', 'City'])\n"
     ]
    }
   ],
   "source": [
    "# Access all of the keys/columns of the dataframe\n",
    "# Dataframe.keys()\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert DataFrame to dictionary and access keys\n",
    "keys = df.to_dict().keys()\n",
    "\n",
    "print(keys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Slicing a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name  Age           City\n",
      "0    Alice   25       New York\n",
      "1      Bob   30  San Francisco\n",
      "2  Charlie   35    Los Angeles\n",
      "3    David   40        Chicago\n",
      "4     Emma   22         Boston\n",
      "\n",
      "Subset using iloc:\n",
      "      Name  Age           City\n",
      "1      Bob   30  San Francisco\n",
      "2  Charlie   35    Los Angeles\n",
      "3    David   40        Chicago\n",
      "\n",
      "Subset using loc:\n",
      "      Name  Age           City\n",
      "1      Bob   30  San Francisco\n",
      "2  Charlie   35    Los Angeles\n",
      "3    David   40        Chicago\n"
     ]
    }
   ],
   "source": [
    "# printing all data for context\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "        'Age': [25, 30, 35, 40, 22],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles', 'Chicago', 'Boston']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Printing the entire DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Slicing using iloc (index-based slicing)\n",
    "subset_iloc = df.iloc[1:4, :]  # Rows 1 to 3, all columns\n",
    "print(\"\\nSubset using iloc:\")\n",
    "print(subset_iloc)\n",
    "\n",
    "# Slicing using loc (label-based slicing)\n",
    "subset_loc = df.loc[1:3, :]  # Rows with index labels 1 to 3, all columns\n",
    "print(\"\\nSubset using loc:\")\n",
    "print(subset_loc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-In Methods <br>\n",
    "\n",
    "<p>These are methods that are frequently used when using Pandas to make your life easier. It is possible to spend a whole week simply exploring the built-in functions supported by DataFrames in Pandas. Here however, we will simply highlight a few ones that might be useful, to give you an idea of what's possible out of the box with Pandas:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1 Column2\n",
      "0        1       A\n",
      "1        2       B\n",
      "2        3       C\n",
      "3        4       D\n",
      "4        5       E\n"
     ]
    }
   ],
   "source": [
    "# DataFrame.head()  -- Accepts integer parameter(gives access to more rows)\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'df'\n",
    "df = pd.DataFrame({\n",
    "    'Column1': [1, 2, 3, 4, 5],\n",
    "    'Column2': ['A', 'B', 'C', 'D', 'E']\n",
    "})\n",
    "\n",
    "# The default behavior of head() is to display the first 5 rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age     City\n",
      "3  David   40  Chicago\n",
      "4  Emily   22   Boston\n"
     ]
    }
   ],
   "source": [
    "# DataFrame.tail()  -- Accepts integer parameter(gives access to more rows)\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],\n",
    "        'Age': [25, 30, 35, 40, 22],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles', 'Chicago', 'Boston']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Using tail() to display the last 2 rows of the DataFrame\n",
    "last_rows = df.tail(2)\n",
    "print(last_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "# The dataframe has a shape property, just like a NumPy matrix. \n",
    "# print(df.shape) -- DataFrame.shape -- No Parameter\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the shape of the DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### describe() <br>\n",
    "<p>Probably one of the most important methods to understand...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              A          B           C\n",
      "count  5.000000   5.000000    5.000000\n",
      "mean   3.000000  30.000000  300.000000\n",
      "std    1.581139  15.811388  158.113883\n",
      "min    1.000000  10.000000  100.000000\n",
      "25%    2.000000  20.000000  200.000000\n",
      "50%    3.000000  30.000000  300.000000\n",
      "75%    4.000000  40.000000  400.000000\n",
      "max    5.000000  50.000000  500.000000\n"
     ]
    }
   ],
   "source": [
    "# Collect summary statistics in one line\n",
    "# DataFrame.describe() -- Accepts parameters (include, exclude)\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [10, 20, 30, 40, 50],\n",
    "        'C': [100, 200, 300, 400, 500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use describe() on the DataFrame\n",
    "summary_stats = df.describe()\n",
    "\n",
    "# Display the summary statistics\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B   C\n",
      "3  1  1   4\n",
      "0  1  4  10\n",
      "1  2  3   8\n",
      "2  3  2   6\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(sorted_df)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Assuming 'data' is a pandas DataFrame\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m sorted_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mages\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "# Sort based on many labels, with left-to-right priority\n",
    "# sorted_data = data.sort_values('ages').reset_index()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'A': [1, 2, 3, 1],\n",
    "        'B': [4, 3, 2, 1],\n",
    "        'C': [10, 8, 6, 4]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort based on multiple columns with left-to-right priority\n",
    "sorted_df = df.sort_values(by=['A', 'B', 'C'])\n",
    "\n",
    "print(sorted_df)\n",
    "\n",
    "# Assuming 'data' is a pandas DataFrame\n",
    "sorted_data = data.sort_values('ages').reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### .columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Age', 'City'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# will show all cols headers\n",
    "# DataFrame.columns -- has no parameters\n",
    "\n",
    "\n",
    "# Keys brings back the 'index' of whatever data type we are working with \n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying column headers\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Class Exercise #2 - Describe & Sort Boston Red Sox Hitting Data <br>\n",
    "<p>Take the data that you read in earlier from the Red Sox csv's and use the describe method to understand the data better. Compare the two years and decide which team is having the better year. Then sort the values based on Batting Average.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of 2017 data:\n",
      "             Rk        Age           G          PA          AB           R  \\\n",
      "count  23.00000  23.000000   23.000000   23.000000   23.000000   23.000000   \n",
      "mean   12.00000  27.478261   72.086957  274.565217  245.521739   34.130435   \n",
      "std     6.78233   4.110624   52.747178  236.592059  209.032157   30.804817   \n",
      "min     1.00000  20.000000    2.000000    1.000000    1.000000    0.000000   \n",
      "25%     6.50000  24.000000   28.500000   74.500000   67.000000    8.500000   \n",
      "50%    12.00000  27.000000   64.000000  188.000000  171.000000   30.000000   \n",
      "75%    17.50000  30.000000  119.000000  502.000000  444.000000   52.000000   \n",
      "max    23.00000  36.000000  153.000000  712.000000  628.000000  101.000000   \n",
      "\n",
      "                H         2B         3B         HR  ...        OBP        SLG  \\\n",
      "count   23.000000  23.000000  23.000000  23.000000  ...  23.000000  23.000000   \n",
      "mean    63.434783  13.086957   0.826087   7.304348  ...   0.346217   0.393348   \n",
      "std     55.645653  12.630817   1.466355   8.309003  ...   0.153742   0.156269   \n",
      "min      1.000000   0.000000   0.000000   0.000000  ...   0.111000   0.200000   \n",
      "25%     18.000000   2.000000   0.000000   0.000000  ...   0.298500   0.330500   \n",
      "50%     53.000000  12.000000   0.000000   5.000000  ...   0.325000   0.387000   \n",
      "75%    118.500000  19.000000   1.500000  10.000000  ...   0.348000   0.426500   \n",
      "max    166.000000  46.000000   6.000000  24.000000  ...   1.000000   1.000000   \n",
      "\n",
      "             OPS        OPS+          TB        GDP        HBP         SH  \\\n",
      "count  23.000000   23.000000   23.000000  23.000000  23.000000  23.000000   \n",
      "mean    0.739609   93.521739  100.086957   6.130435   2.304348   0.347826   \n",
      "std     0.298278   78.686299   91.930267   5.786382   2.566122   0.775107   \n",
      "min     0.333000  -16.000000    1.000000   0.000000   0.000000   0.000000   \n",
      "25%     0.625000   63.000000   22.500000   1.500000   0.000000   0.000000   \n",
      "50%     0.709000   88.000000   89.000000   4.000000   2.000000   0.000000   \n",
      "75%     0.764500   99.500000  176.500000  10.000000   3.000000   0.000000   \n",
      "max     2.000000  428.000000  288.000000  17.000000   9.000000   3.000000   \n",
      "\n",
      "              SF        IBB  \n",
      "count  23.000000  23.000000  \n",
      "mean    1.565217   2.086957  \n",
      "std     2.149547   3.073539  \n",
      "min     0.000000   0.000000  \n",
      "25%     0.000000   0.000000  \n",
      "50%     1.000000   0.000000  \n",
      "75%     2.000000   4.000000  \n",
      "max     8.000000   9.000000  \n",
      "\n",
      "[8 rows x 26 columns]\n",
      "\n",
      "Description of 2018 data:\n",
      "             Rk        Age           G          PA          AB           R  \\\n",
      "count  20.00000  20.000000   20.000000   20.000000   20.000000   20.000000   \n",
      "mean   10.50000  29.100000   82.350000  314.100000  280.200000   43.600000   \n",
      "std     5.91608   4.666792   52.916294  230.972065  203.871631   38.293053   \n",
      "min     1.00000  21.000000    2.000000    7.000000    6.000000    0.000000   \n",
      "25%     5.75000  25.000000   37.000000  125.500000  115.250000   16.500000   \n",
      "50%    10.50000  29.500000   85.500000  278.500000  258.000000   29.000000   \n",
      "75%    15.25000  32.500000  129.250000  510.250000  475.500000   62.250000   \n",
      "max    20.00000  37.000000  150.000000  661.000000  579.000000  129.000000   \n",
      "\n",
      "                H         2B         3B         HR  ...        OBP        SLG  \\\n",
      "count   20.000000  20.000000  20.000000  20.000000  ...  20.000000  20.000000   \n",
      "mean    75.250000  17.650000   1.550000  10.400000  ...   0.307700   0.387500   \n",
      "std     62.462515  15.624795   1.959457  11.722224  ...   0.068843   0.135884   \n",
      "min      1.000000   0.000000   0.000000   0.000000  ...   0.143000   0.091000   \n",
      "25%     28.000000   6.000000   0.000000   1.000000  ...   0.262000   0.304000   \n",
      "50%     49.500000  11.000000   0.500000   6.500000  ...   0.305500   0.399000   \n",
      "75%    115.000000  26.250000   3.000000  15.250000  ...   0.360500   0.441000   \n",
      "max    188.000000  47.000000   6.000000  43.000000  ...   0.438000   0.640000   \n",
      "\n",
      "             OPS        OPS+          TB        GDP        HBP         SH  \\\n",
      "count  20.000000   20.000000   20.000000  20.000000  20.000000  20.000000   \n",
      "mean    0.695200   86.450000  127.200000   6.500000   2.750000   0.350000   \n",
      "std     0.200419   52.199491  113.226183   5.633546   3.274704   0.812728   \n",
      "min     0.310000  -17.000000    1.000000   0.000000   0.000000   0.000000   \n",
      "25%     0.588000   59.500000   37.500000   1.000000   0.000000   0.000000   \n",
      "50%     0.712500   91.000000   72.500000   5.500000   2.000000   0.000000   \n",
      "75%     0.788000  112.500000  192.000000   9.000000   4.250000   0.000000   \n",
      "max     1.078000  186.000000  358.000000  19.000000  11.000000   3.000000   \n",
      "\n",
      "              SF        IBB  \n",
      "count  20.000000  20.000000  \n",
      "mean    2.400000   1.900000  \n",
      "std     2.436564   3.110255  \n",
      "min     0.000000   0.000000  \n",
      "25%     0.000000   0.000000  \n",
      "50%     2.000000   0.000000  \n",
      "75%     4.250000   2.250000  \n",
      "max     7.000000  11.000000  \n",
      "\n",
      "[8 rows x 26 columns]\n",
      "\n",
      "2017 was a better year.\n",
      "\n",
      "2017 was a better year.\n",
      "\n",
      "Top batting averages for 2017:\n",
      "22    1.000\n",
      "12    0.321\n",
      "2     0.293\n",
      "0     0.290\n",
      "4     0.284\n",
      "18    0.276\n",
      "3     0.273\n",
      "5     0.271\n",
      "17    0.268\n",
      "7     0.264\n",
      "16    0.263\n",
      "19    0.250\n",
      "1     0.246\n",
      "6     0.245\n",
      "8     0.242\n",
      "10    0.235\n",
      "9     0.225\n",
      "14    0.224\n",
      "15    0.212\n",
      "11    0.211\n",
      "21    0.200\n",
      "13    0.200\n",
      "20    0.111\n",
      "Name: BA, dtype: float64\n",
      "\n",
      "Top batting averages for 2018:\n",
      "7     0.346\n",
      "8     0.330\n",
      "5     0.290\n",
      "3     0.288\n",
      "13    0.279\n",
      "9     0.277\n",
      "2     0.265\n",
      "12    0.254\n",
      "15    0.246\n",
      "1     0.245\n",
      "14    0.242\n",
      "4     0.240\n",
      "6     0.234\n",
      "11    0.229\n",
      "16    0.222\n",
      "10    0.207\n",
      "0     0.177\n",
      "19    0.167\n",
      "17    0.130\n",
      "18    0.091\n",
      "Name: BA, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from CSV files\n",
    "data_2017 = pd.read_csv('Boston Red Sox hitting data 2017.csv')\n",
    "data_2018 = pd.read_csv('Boston Red Sox hitting data 2018.csv')\n",
    "\n",
    "# Describe data for 2017\n",
    "description_2017 = data_2017.describe()\n",
    "print(\"Description of 2017 data:\")\n",
    "print(description_2017)\n",
    "\n",
    "# Describe data for 2018\n",
    "description_2018 = data_2018.describe()\n",
    "print(\"\\nDescription of 2018 data:\")\n",
    "print(description_2018)\n",
    "\n",
    "# Compare mean batting average for 2017 and 2018\n",
    "mean_batting_avg_2017 = data_2017['BA'].mean()\n",
    "mean_batting_avg_2018 = data_2018['BA'].mean()\n",
    "\n",
    "if mean_batting_avg_2017 > mean_batting_avg_2018:\n",
    "    print(\"\\n2017 was a better year.\")\n",
    "elif mean_batting_avg_2017 < mean_batting_avg_2018:\n",
    "    print(\"\\n2018 was a better year.\")\n",
    "else:\n",
    "    print(\"\\nBoth years had similar performance in terms of mean batting average.\")\n",
    "\n",
    " # Compare mean batting average for 2017 and 2018\n",
    "mean_batting_avg_2017 = data_2017['BA'].mean()\n",
    "mean_batting_avg_2018 = data_2018['BA'].mean()\n",
    "\n",
    "if mean_batting_avg_2017 > mean_batting_avg_2018:\n",
    "    print(\"\\n2017 was a better year.\")\n",
    "elif mean_batting_avg_2017 < mean_batting_avg_2018:\n",
    "    print(\"\\n2018 was a better year.\")\n",
    "else:\n",
    "    print(\"\\nBoth years had similar performance in terms of mean batting average.\")\n",
    "    \n",
    "# Sort values based on Batting Average for 2017\n",
    "sorted_data_2017 = data_2017.sort_values(by='BA', ascending=False)\n",
    "print(\"\\nTop batting averages for 2017:\")\n",
    "print(sorted_data_2017['BA'])\n",
    "\n",
    "# Sort values based on Batting Average for 2018\n",
    "sorted_data_2018 = data_2018.sort_values(by='BA', ascending=False)\n",
    "print(\"\\nTop batting averages for 2018:\")\n",
    "print(sorted_data_2018['BA'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtration <br>\n",
    "<p>Let's look at how to filter dataframes for rows that fulfill a specific conditon.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Salary\n",
      "0    Alice   25   50000\n",
      "1      Bob   30   60000\n",
      "2  Charlie   22   45000\n",
      "3    David   35   70000\n",
      "4    Emily   28   55000\n",
      "    Name  Age  Salary\n",
      "1    Bob   30   60000\n",
      "3  David   35   70000\n",
      "4  Emily   28   55000\n"
     ]
    }
   ],
   "source": [
    "# Conditional boolean dataframe\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],\n",
    "    'Age': [25, 30, 22, 35, 28],\n",
    "    'Salary': [50000, 60000, 45000, 70000, 55000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Filter rows where Age is greater than 25\n",
    "filtered_df = df[df['Age'] > 25]\n",
    "print(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age           City\n",
      "1    Bob   30  San Francisco\n",
      "3  David   35        Chicago\n",
      "  Name  Age           City\n",
      "1  Bob   30  San Francisco\n"
     ]
    }
   ],
   "source": [
    "# exactly like numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Age': [25, 30, 22, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Example 1: Filter rows where Age is greater than 25\n",
    "condition = df['Age'] > 25\n",
    "filtered_df = df[condition]\n",
    "print(filtered_df)\n",
    "\n",
    "# Example 2: Filter rows where Age is greater than 25 and City is 'San Francisco'\n",
    "condition = (df['Age'] > 25) & (df['City'] == 'San Francisco')\n",
    "filtered_df = df[condition]\n",
    "print(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transformations <br>\n",
    "<p>Rarely, if ever, will the columns in the original raw dataframe read from CSV or database table be the ones you actually need for your analysis. You will spend lots of time constantly transforming columns or groups of columns using general computational operations to produce new ones that are functions of the old ones. Pandas has full support for this: Consider the following dataframe containing membership term and renewal number for a group of customers:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some fake data\n",
    "import pandas as pd\n",
    "\n",
    "# Generate some fake data\n",
    "data = {'customer_id': [1, 2, 3, 4, 5],\n",
    "        'membership_term': [6, 12, 6, 12, 6],\n",
    "        'renewal_number': [1, 2, 1, 3, 1]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Create a new column 'total_duration'\n",
    "df['total_duration'] = df['membership_term'] * df['renewal_number']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating a New Column w/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   membership_term  renewal_number  total_months\n",
      "0                6               1             6\n",
      "1               12               2            24\n",
      "2                3               1             3\n",
      "3                6               3            18\n",
      "4               12               2            24\n"
     ]
    }
   ],
   "source": [
    "# DataFrame['key'] = Some Calculation from our DataFrame Columns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame df with columns 'membership_term' and 'renewal_number'\n",
    "data = {'membership_term': [6, 12, 3, 6, 12],\n",
    "        'renewal_number': [1, 2, 1, 3, 2]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Let's say you want to create a new column 'total_months' by multiplying 'membership_term' and 'renewal_number'\n",
    "df['total_months'] = df['membership_term'] * df['renewal_number']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User Defined Function\n",
    "\n",
    "<p>If what you want to do to a column that can't be represented by simple mathematical operations, you can write your own $\\textit{user defined function}$ with the full customizability available in Python and any external Python packages, then map it directly onto a column. Let's add some ages to our customer dataframe, and then classify them into our custom defined grouping scheme:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id        name  gender  ages age_group\n",
      "0            1   Customer1    Male    20     18-24\n",
      "1            2   Customer2  Female    68       55+\n",
      "2            3   Customer3    Male    41     35-44\n",
      "3            4   Customer4  Female    60       55+\n",
      "4            5   Customer5    Male    39     35-44\n",
      "5            6   Customer6    Male    22     18-24\n",
      "6            7   Customer7  Female    51     45-54\n",
      "7            8   Customer8    Male    25     25-34\n",
      "8            9   Customer9  Female    43     35-44\n",
      "9           10  Customer10    Male    30     25-34\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample customer dataframe\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': range(1, 11),\n",
    "    'name': ['Customer{}'.format(i) for i in range(1, 11)],\n",
    "    'gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male']\n",
    "})\n",
    "\n",
    "# Create a new column for ages\n",
    "customers['ages'] = np.random.randint(18, 70, 10)\n",
    "\n",
    "# User defined function for age grouping\n",
    "def make_age_groups(age):\n",
    "    if age < 25:\n",
    "        return '18-24'\n",
    "    elif 25 <= age < 35:\n",
    "        return '25-34'\n",
    "    elif 35 <= age < 45:\n",
    "        return '35-44'\n",
    "    elif 45 <= age < 55:\n",
    "        return '45-54'\n",
    "    else:\n",
    "        return '55+'\n",
    "\n",
    "# Apply the age grouping function to create a new column 'age_group'\n",
    "customers['age_group'] = customers['ages'].apply(make_age_groups)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(customers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As a last example I'll show here how you would use a lambda function to create a UDF that depends on $\\textit{more than one}$ column:</p>\n",
    "\n",
    "<li>UDF = User Defined Function</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column1  column2  result_column\n",
      "0        1        5              6\n",
      "1        2        6              8\n",
      "2        3        7             10\n",
      "3        4        8             12\n"
     ]
    }
   ],
   "source": [
    "#Axis for apply can only be 1 or 0 -- 1 being the X axis 0 being the Y axis\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'column1': [1, 2, 3, 4],\n",
    "        'column2': [5, 6, 7, 8]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a lambda function that takes two columns and performs a custom operation\n",
    "custom_function = lambda x, y: x + y  # You can replace this with your own operation\n",
    "\n",
    "# Apply the lambda function to create a new column\n",
    "df['result_column'] = df.apply(lambda row: custom_function(row['column1'], row['column2']), axis=1)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Class Exercise #3 - Create Your Own UDF <br>\n",
    "<p>Using the Boston Red Sox data, create your own UDF which creates a new column called 'All-Star' and puts every player with either a batting average over .280 or an on base percentage of over .360 with a result of 'Yes' in the column and 'No' if not.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name     BA    OBP AllStar\n",
      "0  Player1  0.233  0.360      No\n",
      "1  Player2  0.150  0.288      No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Player1', 'Player2'],\n",
    "    'BA': [0.233, 0.150],\n",
    "    'OBP': [0.360, 0.288]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to determine All-Star status\n",
    "def is_all_star(row):\n",
    "    return 'Yes' if row['BA'] > 0.280 or row['OBP'] > 0.360 else 'No'\n",
    "\n",
    "# Apply the function to create the 'AllStar' column\n",
    "df['AllStar'] = df.apply(is_all_star, axis=1)\n",
    "\n",
    "# Display the result\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations <br>\n",
    "<p>The raw data plus some transformations is generally only half the story. Your objective is to extract actual insights and actionable conclusions from the data, and that means reducing it from potentially billions of rows to some summary statistics via aggregation functions.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### groupby() <br>\n",
    "<p>The .groupby() function is in some ways a 'master' aggregation.</p> \n",
    "\n",
    "<p>Data tables will usually reserve one column as a primary key - that is, a column for which each row has a unique value. This is to facilitate access to the exact rows of a data table that a user wants to view. The other columns will often have repeated values, such as the age groups in the above examples. We can use these columns to explore the data using the Pandas API:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "# also introducing .count() here, exact same as to how it's used in SQL\n",
    "\n",
    "# Using the groupby with the column intact as a column/key\n",
    "# customers.groupby('age_group', as_index = False).count()[['customer_id','age_group']]\n",
    "\n",
    "customers.groupby('age_group').count()\n",
    "print(type(customers.groupby('age_group')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Type of groupby()\n",
    "\n",
    "<p>The result is a new dataframe, the columns of which all contain the counts of the grouped field. Notice the type of a grouped dataframe:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Value\n",
      "Category       \n",
      "A            37\n",
      "B            63\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "        'Value': [10, 20, 15, 25, 12, 18]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by 'Category'\n",
    "grouped_df = df.groupby('Category')\n",
    "\n",
    "# Applying sum() to get the sum of 'Value' for each category\n",
    "result_df = grouped_df.sum()\n",
    "\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This is because simply grouping data doesn't quite make sense without an aggregation function like count() to pair with. In this case, we're counting occurances of the grouped field, but that's not all we can do. We can take averages, standard deviations, mins, maxes and much more! Let's see how this works a bit more:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "A    20.0\n",
      "B    25.0\n",
      "Name: Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# mean = average\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "        'Value': [10, 15, 20, 25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by 'Category' and calculate the mean for each group\n",
    "mean_values = df.groupby('Category')['Value'].mean()\n",
    "\n",
    "print(mean_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### groupby() w/Multiple Columns\n",
    "\n",
    "<p>We end up with the average age of the groups in the last column, the average tenure in the tenure column, and so on and so forth. You can even split the groups more finely by passing a list of columns to group by:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Department Employee   Age  Tenure\n",
      "0         HR    Alice  25.0     2.0\n",
      "1         HR  Charlie  35.0     7.0\n",
      "2         HR    Frank  40.0     8.0\n",
      "3         IT      Bob  30.0     5.0\n",
      "4         IT    David  28.0     3.0\n",
      "5         IT      Eve  32.0     4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Department': ['HR', 'IT', 'HR', 'IT', 'IT', 'HR'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'Age': [25, 30, 35, 28, 32, 40],\n",
    "    'Tenure': [2, 5, 7, 3, 4, 8]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by multiple columns and calculate average\n",
    "grouped_df = df.groupby(['Department', 'Employee']).agg({\n",
    "    'Age': 'mean',\n",
    "    'Tenure': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(grouped_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### drop_duplicates()\n",
    "\n",
    "<p>Drops all duplicates from the current dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   A       B\n",
      "0  1   apple\n",
      "1  2  banana\n",
      "2  2  banana\n",
      "3  3  cherry\n",
      "4  4    date\n",
      "5  4    date\n",
      "\n",
      "DataFrame after dropping duplicates:\n",
      "   A       B\n",
      "0  1   apple\n",
      "1  2  banana\n",
      "3  3  cherry\n",
      "4  4    date\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'A': [1, 2, 2, 3, 4, 4],\n",
    "        'B': ['apple', 'banana', 'banana', 'cherry', 'date', 'date']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Dropping duplicates\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "# Displaying the DataFrame after removing duplicates\n",
    "print(\"\\nDataFrame after dropping duplicates:\")\n",
    "print(df_no_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping duplicates based on column 'A':\n",
      "   A       B\n",
      "0  1   apple\n",
      "1  2  banana\n",
      "3  3  cherry\n",
      "4  4    date\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on a subset of columns\n",
    "df_subset_no_duplicates = df.drop_duplicates(subset=['A'])\n",
    "\n",
    "# Displaying the DataFrame after dropping duplicates based on column 'A'\n",
    "print(\"\\nDataFrame after dropping duplicates based on column 'A':\")\n",
    "print(df_subset_no_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer data has been written to customer_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Send customer data into a CSV file\n",
    "import csv\n",
    "\n",
    "# Sample customer data\n",
    "customer_data = [\n",
    "    {\"Name\": \"Ola Kufo\", \"Email\": \"kunlekufo@yahoo.com.com\", \"Phone\": \"123-456-7890\"},\n",
    "    {\"Name\": \"Anjola Kufo\", \"Email\": \"kunlekufo@gmail.com\", \"Phone\": \"987-654-3210\"},\n",
    "  \n",
    "]\n",
    "\n",
    "\n",
    "csv_file_path = \"customer_data.csv\"\n",
    "\n",
    "# Writing to CSV file\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Name\", \"Email\", \"Phone\"])\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the customer data\n",
    "    writer.writerows(customer_data)\n",
    "\n",
    "print(f\"Customer data has been written to {csv_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Thus the groupby operation allows you to rapidly make summary observations about the state of your entire dataset at flexible granularity. In one line above, we actually did something very complicated - that's the power of the dataframe. In fact, the process often consists of several iterative groupby operations, each revealing greater insight than the last - if you don't know where to start with a dataset, try a bunch of groupbys!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework Excersise #1 - Find the Total Number of Runs and RBIs for the Red Sox <br>\n",
    "<p>Get total number of home runs and rbi's</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Runs and RBIs for the Red Sox in 2017:\n",
      "       HR  RBI\n",
      "Team          \n",
      "BOS   168  735\n",
      "\n",
      "Total Runs and RBIs for the Red Sox in 2018:\n",
      "       HR  RBI\n",
      "Team          \n",
      "BOS   208  826\n"
     ]
    }
   ],
   "source": [
    "# step 1: Add a new column with the key 'Team' and all column values should be 'BOS'\n",
    "\n",
    "\n",
    "# step 2: Group by the 'Team' column and get total home runs and rbi's\n",
    "\n",
    "# Produce data for both 2017 and 2018 (ie print both seperated by a newline character \\n)\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df_2017 = pd.read_csv('Boston Red Sox hitting data 2017.csv')\n",
    "df_2018 = pd.read_csv('Boston Red Sox hitting data 2018.csv')\n",
    "\n",
    "# Step 1: Add a new column with the key 'Team', and all column values should be 'BOS'\n",
    "df_2017['Team'] = 'BOS'\n",
    "df_2018['Team'] = 'BOS'\n",
    "\n",
    "# Step 2: Group by the 'Team' column and get total home runs and RBI's\n",
    "result_2017 = df_2017.groupby('Team')[['HR', 'RBI']].sum()\n",
    "result_2018 = df_2018.groupby('Team')[['HR', 'RBI']].sum()\n",
    "\n",
    "# Print the results\n",
    "print('Total Runs and RBIs for the Red Sox in 2017:')\n",
    "print(result_2017)\n",
    "\n",
    "print('\\nTotal Runs and RBIs for the Red Sox in 2018:')\n",
    "print(result_2018)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the average age of runners in the 2017 Boston Marathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average age of runners is: 42.59 years\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = 'boston_marathon2017_edited - boston_marathon2017_edited.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the average age\n",
    "average_age = data['Age'].mean()\n",
    "\n",
    "# Print the result\n",
    "print(f'The average age of runners is: {average_age:.2f} years')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
